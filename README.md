# ğŸ§  MathAI â€“ Libreria Java didattica per lâ€™Intelligenza Artificiale

**MathAI** Ã¨ una libreria Java pensata per lâ€™insegnamento dellâ€™Intelligenza Artificiale
nel **liceo scientifico â€“ indirizzo matematico / scienze applicate**, in particolare per il **liceo matematico**.

La libreria permette di programmare:

* **regressione lineare**
* **reti neurali feed-forward**
* esempi classici come **AND**, **OR**, **XOR**
* sia in **1D** che in **ND (input vettoriale)**

ğŸ‘‰ con **codice semplice**, **senza array di array**, e con concetti coerenti con la teoria.

---

## ğŸ¯ Obiettivi didattici

* Separare chiaramente:

  * **input**
  * **modello**
  * **addestramento**
* Rendere il codice:

  * leggibile dagli studenti
  * modificabile
  * riutilizzabile
* Evitare costrutti avanzati non ancora studiati
* Collegare direttamente:

  * formule matematiche
  * codice Java

---

## ğŸ“¦ Struttura del progetto

```
src/
â””â”€â”€ math_ai/
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ InputValue.java
    â”‚   â”œâ”€â”€ Model.java
    â”‚   â””â”€â”€ Trainable.java
    â”‚
    â”œâ”€â”€ math/
    â”‚   â””â”€â”€ VectorMath.java
    â”‚
    â”œâ”€â”€ regression/
    â”‚   â””â”€â”€ LinearRegression1D.java
    â”‚
    â””â”€â”€ neural/
        â”œâ”€â”€ Activation.java
        â”œâ”€â”€ ActivationFunctions.java
        â”œâ”€â”€ Layer.java
        â”œâ”€â”€ NeuralLayer.java
        â””â”€â”€ NeuralNetwork.java
```

---

## ğŸ§© Concetti fondamentali

### ğŸ”¹ `InputValue`

Rappresenta **lâ€™input di un modello**.

* puÃ² essere **scalare** (1 valore)
* oppure **vettoriale** (piÃ¹ valori)
* nasconde completamente lâ€™uso degli array agli studenti

```java
InputValue x1 = new InputValue(3);        // input 1D
InputValue x2 = new InputValue(1, 0, 1);  // input ND
```

---

### ğŸ”¹ `Model`

Classe astratta base per **tutti i modelli**.

```java
public abstract class Model {
    public abstract double predict(InputValue x);
}
```

* lâ€™output Ã¨ **sempre un `double`**
* sia per regressione che per reti neurali

---

### ğŸ”¹ `Trainable`

Interfaccia per i modelli che possono essere **addestrati**.

```java
void train(InputValue[] X, double[] Y, double lr, int epochs);
```

Include anche il calcolo automatico della **loss MSE**.

---

## ğŸ“ˆ Regressione lineare

### `LinearRegression1D`

Modello del tipo:

[
y = m \cdot x + q
]

* addestramento con **discesa del gradiente**
* funzione di errore: **Mean Squared Error**

### Esempio

```java
InputValue[] X = {
    new InputValue(1),
    new InputValue(2),
    new InputValue(3),
    new InputValue(4)
};

double[] Y = {2, 4, 6, 8};

LinearRegression1D model = new LinearRegression1D();
model.train(X, Y, 0.01, 3000);

System.out.println(model.predict(new InputValue(5)));
```

---

## ğŸ§  Reti neurali

### ğŸ”¹ `NeuralLayer`

Un **vero layer neurale**, composto da:

* pesi
* bias
* funzione di attivazione

ğŸ‘‰ **Dense + Activation sono unâ€™unica entitÃ **, non due layer separati.

```java
NeuralLayer layer = new NeuralLayer(
    inputSize,
    outputSize,
    Activation.SIGMOID
);
```

---

### ğŸ”¹ `NeuralNetwork`

Rete neurale feed-forward composta da piÃ¹ `NeuralLayer`.

* input: `InputValue`
* output: `double`
* supporta input **1D e ND**
* backpropagation implementata internamente

### Esempio: XOR

```java
NeuralNetwork nn = new NeuralNetwork();

nn.add(new NeuralLayer(2, 3, Activation.SIGMOID));
nn.add(new NeuralLayer(3, 1, Activation.SIGMOID));

InputValue[] X = {
    new InputValue(0,0),
    new InputValue(0,1),
    new InputValue(1,0),
    new InputValue(1,1)
};

double[] Y = {0, 1, 1, 0};

nn.train(X, Y, 0.1, 10000);

System.out.println(nn.predict(new InputValue(1,0)));
```

---

## ğŸ§® Funzioni matematiche

### `VectorMath`

Classe di supporto con funzioni di errore:

* MSE
* RMSE
* MAE

Esempio:

```java
double mse = VectorMath.mse(X, Y, model);
```

---

## ğŸ§  Scelte progettuali (perchÃ© Ã¨ fatta cosÃ¬)

* **Output sempre scalare**
  â†’ semplifica enormemente lâ€™uso didattico

* **Input incapsulato in `InputValue`**
  â†’ niente `double[][]`, niente confusione

* **Un solo tipo di layer neurale**
  â†’ coerente con la teoria: *un layer = pesi + attivazione*

* **1D e ND con lo stesso codice**
  â†’ il caso 1D Ã¨ solo un ND con un valore

---

## ğŸ“ Destinatari

* studenti del **liceo scientifico**
* corsi di **AI introduttiva**
* docenti che vogliono esempi di AI **programmata**, non â€œmagicaâ€

---

## ğŸ“œ Licenza

[Gpl 3.0](https://github.com/Liceo-Matematico/mathAI?tab=GPL-3.0-1-ov-file#readme)

---
